{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wakachii/SI-Org-chart/blob/main/pipeline/master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "392a2h2eMhAZ"
      },
      "source": [
        "### Please run with Google Colab with Good GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ugecLY7EMhAc",
        "outputId": "e34d5095-85e1-40ea-9e24-8651546b3719",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev tesseract-ocr tesseract-ocr-eng\n",
            "  tesseract-ocr-jpn tesseract-ocr-osd\n",
            "0 upgraded, 7 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 9,949 kB of archives.\n",
            "After this operation, 34.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1.3 [581 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-jpn all 1:4.00~git30-7274cfa-1.1 [1,390 kB]\n",
            "Fetched 9,949 kB in 3s (3,365 kB/s)\n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libarchive-dev_3.6.0-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.3) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../1-libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../2-libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "Preparing to unpack .../3-tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../4-tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../5-tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Selecting previously unselected package tesseract-ocr-jpn.\n",
            "Preparing to unpack .../6-tesseract-ocr-jpn_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-jpn (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.3) ...\n",
            "Setting up tesseract-ocr-jpn (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m169.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Detectron2 has not released pre-built binaries for the latest pytorch (https://github.com/facebookresearch/detectron2/issues/4053)\n",
        "# so we install from source instead. This takes a few minutes.\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git' -q\n",
        "!apt install tesseract-ocr libtesseract-dev tesseract-ocr-jpn -q\n",
        "!pip install pyocr -q\n",
        "!pip install layoutparser -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gMv0VPNrMhAd",
        "outputId": "51d70d51-7e7e-4cc8-a7c2-0e14a0244f0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import json\n",
        "import pyocr\n",
        "import cv2 as cv2\n",
        "from tqdm import tqdm\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import layoutparser as lp\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IOKpd0KkMhAe"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/scan_org_charts/\"\n",
        "# data\n",
        "path_2010 = path + \"2010\"\n",
        "path_2006 = path + \"2006\"\n",
        "path_2002 = path + \"2002\"\n",
        "path_clean = path + \"clean\"\n",
        "# trimming\n",
        "path_renamed = path + \"renamed/\"\n",
        "path_cropped = path + \"cropped/\"\n",
        "# model\n",
        "path_learn = path + \"learning/\"\n",
        "path_train = path_learn + \"data/train\"\n",
        "path_coco = path_learn + \"Org_chart-1.json\"\n",
        "path_data = path + \"cropped\"\n",
        "path_json = path_learn + \"output\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDSe5J8-MhAe"
      },
      "source": [
        "## load image and rename with OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ad-1ThMuMhAf",
        "outputId": "8fa840e3-68fc-4386-9f2f-a76e94f18dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing files:   0%|          | 0/122 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/histogram.cpp:3440: error: (-215:Assertion failed) _src.type() == CV_8UC1 in function 'equalizeHist'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-bf46ce0d5c9b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m350\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mgray_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgray_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequalizeHist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mgray_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     binary_image = cv2.adaptiveThreshold(\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/histogram.cpp:3440: error: (-215:Assertion failed) _src.type() == CV_8UC1 in function 'equalizeHist'\n"
          ]
        }
      ],
      "source": [
        "# 2002\n",
        "files_2002 = os.listdir(path_2002)\n",
        "files_2002 = [f for f in files_2002 if os.path.isfile(os.path.join(path_2002, f))]\n",
        "files_2002.sort()\n",
        "for i in tqdm(range(len(files_2002)), desc=\"Processing files\"):\n",
        "    # load image\n",
        "    file_2002 = os.path.join(path_2002, files_2002[i])\n",
        "    img = cv2.imread(file_2002)\n",
        "    # preprocessing for OCR\n",
        "    header = img[0:350, 0:-1500]\n",
        "    gray_image = cv2.GaussianBlur(header, (5, 5), 0)\n",
        "    gray_image = cv2.cvtColor(header, cv2.COLOR_BGR2GRAY)\n",
        "    binary_image = cv2.adaptiveThreshold(\n",
        "        gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
        "    )\n",
        "    gray_image_inv = cv2.bitwise_not(binary_image)\n",
        "    pil_image = Image.fromarray(gray_image_inv)\n",
        "    tools = pyocr.get_available_tools()\n",
        "    tool = tools[0]\n",
        "    txt = tool.image_to_string(\n",
        "        pil_image,\n",
        "        lang=\"eng\",\n",
        "        builder=pyocr.builders.TextBuilder(tesseract_layout=6)\n",
        "    )\n",
        "    filtered_text = re.findall(r'\\d+', txt)\n",
        "    if len(filtered_text) > 1:\n",
        "            if len(filtered_text[0]) == 4:\n",
        "                    path_save_2002 = path_renamed + \"2002_\" + filtered_text[0] + \".png\"\n",
        "                    cv2.imwrite(f\"{path_save_2002}\", img)\n",
        "\n",
        "\n",
        "# 2010\n",
        "files_2010 = os.listdir(path_2010)\n",
        "files_2010 = [f for f in files_2010 if os.path.isfile(os.path.join(path_2010, f))]\n",
        "files_2010.sort()\n",
        "for i in tqdm(range(len(files_2010)), desc=\"Processing files\"):\n",
        "    # load image\n",
        "    file_2010 = os.path.join(path_2010, files_2010[i])\n",
        "    img = cv2.imread(file_2010)\n",
        "    # preprocessing for OCR\n",
        "    header = img[50:250, 10:-10]\n",
        "    gray_image = cv2.cvtColor(header, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary_image = cv2.threshold(gray_image, 245, 255, cv2.THRESH_BINARY)\n",
        "    gray_image_inv = cv2.bitwise_not(binary_image)\n",
        "    pil_image = Image.fromarray(gray_image_inv)\n",
        "    # OCR\n",
        "    tools = pyocr.get_available_tools()\n",
        "    tool = tools[0]\n",
        "    txt = tool.image_to_string(\n",
        "        pil_image,\n",
        "        lang=\"jpn\",\n",
        "        builder=pyocr.builders.TextBuilder(tesseract_layout=6)\n",
        "    )\n",
        "    filtered_text = re.findall(r'\\d+', txt)\n",
        "    if len(filtered_text) > 0:\n",
        "            if len(filtered_text[0]) == 4:\n",
        "                    path_save_2010 = path_renamed + \"2010_\" + filtered_text[0] + \".png\"\n",
        "                    cv2.imwrite(f\"{path_save_2010}\", img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gr7cw6AMhAf"
      },
      "source": [
        "## crop org chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMZft8ICMhAf"
      },
      "outputs": [],
      "source": [
        "files_renamed = os.listdir(path_renamed)\n",
        "files_renamed = [f for f in files_renamed if os.path.isfile(os.path.join(path_renamed, f))]\n",
        "files_renamed.sort()\n",
        "model = lp.Detectron2LayoutModel('lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config',\n",
        "                                 extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],\n",
        "                                 label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3:\"Table\", 4:\"Figure\"})\n",
        "\n",
        "\n",
        "for j in tqdm(range(1,len(files_renamed)), desc=\"Processing files\"):\n",
        "    # load image\n",
        "    file = os.path.join(path, files_renamed[j])\n",
        "    img = cv2.imread(file)\n",
        "    # detection\n",
        "    layout = model.detect(img)\n",
        "    lp.draw_box(img, layout, box_width=3)\n",
        "    figures = [block for block in layout if block.type == \"Figure\"]\n",
        "\n",
        "    # crop\n",
        "    for i, figure in enumerate(figures):\n",
        "        x_1, y_1, x_2, y_2 = map(int, figure.coordinates)\n",
        "        cropped_img = img[480:y_2, 50:x_2]\n",
        "        path_save = path_cropped + \"cropped_\" + file\n",
        "        cv2.imwrite(f\"{path_save}\", cropped_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rFc0OYVMhAg"
      },
      "source": [
        "## Detect departments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv7PYQg9MhAg"
      },
      "outputs": [],
      "source": [
        "# set train data\n",
        "register_coco_instances(\"org_chart_train\", {}, path_coco, path_train)\n",
        "\n",
        "# setting for using the model\n",
        "cfg = get_cfg() # initialize\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"org_chart_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.SOLVER.IMS_PER_BATCH = 1\n",
        "cfg.SOLVER.BASE_LR = 0.0004\n",
        "cfg.SOLVER.MAX_ITER = (500)\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (128)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "\n",
        "# train\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True) # for output\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0JB9rHXMhAg"
      },
      "outputs": [],
      "source": [
        "# the function for making the meta-data dict of the test data\n",
        "def get_test_dicts(img_dir):\n",
        "    img_files = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "    dataset_dicts = []\n",
        "    for idx, img_file in enumerate(img_files):\n",
        "        record = {}\n",
        "        record[\"file_name\"] = img_file\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"], record[\"width\"] = cv2.imread(img_file).shape[:2]\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts\n",
        "\n",
        "# change the test data form for dectron2\n",
        "DatasetCatalog.register(\"org_chart_data\", lambda: get_test_dicts(path_data))\n",
        "MetadataCatalog.get(\"org_chart_data\").set(thing_classes=[\"department\"])\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # load trained weights\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6  # score\n",
        "cfg.DATASETS.TEST = (\"org_chart_data\", )  # set the test data to the model\n",
        "\n",
        "# detect departments\n",
        "predictor = DefaultPredictor(cfg)\n",
        "metadata = MetadataCatalog.get(\"org_chart_data\")\n",
        "dataset_dicts = DatasetCatalog.get(\"org_chart_data\")\n",
        "\n",
        "for d in tqdm(dataset_dicts):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(img)\n",
        "    json_output = {\n",
        "    \"file_name\": d[\"file_name\"],\n",
        "    \"pred_boxes\": outputs[\"instances\"].pred_boxes.tensor.cpu().numpy().tolist(),\n",
        "    \"scores\": outputs[\"instances\"].scores.cpu().numpy().tolist(),\n",
        "    \"pred_classes\": outputs[\"instances\"].pred_classes.cpu().numpy().tolist()\n",
        "    }\n",
        "    # save JSON\n",
        "    base_name = os.path.basename(d[\"file_name\"])\n",
        "    json_name = base_name.replace(\".png\", \".json\")\n",
        "    json_path = os.path.join(path_json, json_name)\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump(json_path, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qos9jeIMhAg"
      },
      "outputs": [],
      "source": [
        "files_croppedd = os.listdir(path_cropped)\n",
        "files_croppedd = [f for f in files_croppedd if os.path.isfile(os.path.join(path_cropped, f))]\n",
        "\n",
        "files_json = os.listdir(path_json)\n",
        "files_json = [f for f in files_json if os.path.isfile(os.path.join(path_json, f))]\n",
        "\n",
        "results = []\n",
        "\n",
        "for i in tqdm(range(len(files_croppedd)), desc=\"Processing files\"):\n",
        "    file = os.path.join(path, files_croppedd[i])\n",
        "    file_json = os.path.join(path_json, files_json[i])\n",
        "    image = Image.open(file)\n",
        "    image_width, image_height = image.size\n",
        "    with open(file_json, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    # the coordation of the centers of department\n",
        "    centers = []\n",
        "    for i, box in enumerate(data[\"pred_boxes\"]):\n",
        "        x_center = int((box[0] + box[2]) / 2)\n",
        "        y_center = int((box[1] + box[3]) / 2)\n",
        "\n",
        "        # Normalize the image size\n",
        "        x_normalized = (x_center / image_width) * 10\n",
        "        y_normalized = (y_center / image_height) * 10\n",
        "        centers.append({\"id\": i, \"center\": (x_normalized, y_normalized)})\n",
        "\n",
        "    # make graph\n",
        "    G = nx.Graph()\n",
        "    # Add nodes to graph\n",
        "    for center in centers:\n",
        "        G.add_node(center[\"id\"], pos=center[\"center\"])\n",
        "    # Add edges to graph\n",
        "    distance_threshold = 5\n",
        "    for i in range(len(centers)):\n",
        "        for j in range(i + 1, len(centers)):\n",
        "            dist = np.linalg.norm(np.array(centers[i][\"center\"]) - np.array(centers[j][\"center\"]))\n",
        "            if dist < distance_threshold:\n",
        "                G.add_edge(centers[i][\"id\"], centers[j][\"id\"], weight=dist)\n",
        "\n",
        "    pos = nx.get_node_attributes(G, \"pos\")\n",
        "\n",
        "    num_depart = len(centers)\n",
        "    shortest_length_path = nx.average_shortest_path_length(G)\n",
        "    match = re.search(r\"cropped_(\\d{4})_(\\d{4})\", file)\n",
        "    if match:\n",
        "        year = match.group(1)  # Extracts the year (e.g., \"2002\")\n",
        "        code = match.group(2)  # Extracts the code (e.g., \"7003\")\n",
        "    else:\n",
        "        year = None\n",
        "        code = None\n",
        "\n",
        "    results.append({\"code\": code, \"year\": year , \"shortest_path_length\": shortest_length_path, \"num_depart\": num_depart})\n",
        "\n",
        "data = pd.DataFrame(results)\n",
        "data.to_csv(os.path.join(path_clean, \"org_data.csv\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}