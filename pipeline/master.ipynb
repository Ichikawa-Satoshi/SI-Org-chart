{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wakachii/SI-Org-chart/blob/main/pipeline/master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "392a2h2eMhAZ"
      },
      "source": [
        "### Please run with Google Colab with Good GPU\n",
        "<a href=\"https://colab.research.google.com/github/wakachii/SI-Org-chart/blob/main/pipeline/master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugecLY7EMhAc",
        "outputId": "bbdd8b09-7afa-4714-a356-059fd06e230e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /private/var/folders/mz/k5cvq67n1cdd51htpfqt0wbh0000gn/T/pip-req-build-dfz7zzpi\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /private/var/folders/mz/k5cvq67n1cdd51htpfqt0wbh0000gn/T/pip-req-build-dfz7zzpi\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Detectron2 has not released pre-built binaries for the latest pytorch (https://github.com/facebookresearch/detectron2/issues/4053)\n",
        "# so we install from source instead. This takes a few minutes.\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git' -q\n",
        "\n",
        "!pip install pyocr -q\n",
        "!pip install layoutparser -q\n",
        "\n",
        "# Install pre-built detectron2 that matches pytorch version, if released:\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "#!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/{CUDA_VERSION}/{TORCH_VERSION}/index.html\n",
        "\n",
        "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMv0VPNrMhAd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import json\n",
        "import pyocr\n",
        "import cv2 as cv2\n",
        "from tqdm import tqdm\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import layoutparser as lp\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOKpd0KkMhAe"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/scan_org_charts/\"\n",
        "# data\n",
        "path_2010 = path + \"2010\"\n",
        "path_2006 = path + \"2006\"\n",
        "path_2002 = path + \"2002\"\n",
        "path_clean = path + \"clean\"\n",
        "# trimming\n",
        "path_renamed = path + \"renamed/\"\n",
        "path_cropped = path + \"cropped/\"\n",
        "# model\n",
        "path_learn = path + \"learning/\"\n",
        "path_train = path_learn + \"data/train\"\n",
        "path_coco = path_learn + \"Org_chart-1.json\"\n",
        "path_data = path + \"cropped\"\n",
        "path_json = path_learn + \"output\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDSe5J8-MhAe"
      },
      "source": [
        "## load image and rename with OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad-1ThMuMhAf"
      },
      "outputs": [],
      "source": [
        "# 2002\n",
        "files_2002 = os.listdir(path_2002)\n",
        "files_2002 = [f for f in files_2002 if os.path.isfile(os.path.join(path_2002, f))]\n",
        "files_2002.sort()\n",
        "for i in tqdm(range(len(files_2002)), desc=\"Processing files\"):\n",
        "    # load image\n",
        "    file_2002 = os.path.join(path_2002, files_2002[i])\n",
        "    img = cv2.imread(file_2002)\n",
        "    # preprocessing for OCR\n",
        "    header = img[0:350, 0:-1500]\n",
        "    gray_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "    gray_image = cv2.equalizeHist(gray_image)\n",
        "    gray_image = cv2.cvtColor(header, cv2.COLOR_BGR2GRAY)\n",
        "    binary_image = cv2.adaptiveThreshold(\n",
        "        gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
        "    )\n",
        "    gray_image_inv = cv2.bitwise_not(binary_image)\n",
        "    pil_image = Image.fromarray(gray_image_inv)\n",
        "    tools = pyocr.get_available_tools()\n",
        "    tool = tools[0]\n",
        "    txt = tool.image_to_string(\n",
        "        pil_image,\n",
        "        lang=\"eng\",\n",
        "        builder=pyocr.builders.TextBuilder(tesseract_layout=6)\n",
        "    )\n",
        "    filtered_text = re.findall(r'\\d+', txt)\n",
        "    if len(filtered_text) > 1:\n",
        "            if len(filtered_text[0]) == 4:\n",
        "                    path_save_2002 = path_renamed + \"2002_\" + filtered_text[0] + \".png\"\n",
        "                    cv2.imwrite(f\"{path_save_2002}\", img)\n",
        "\n",
        "\n",
        "# 2010\n",
        "files_2010 = os.listdir(path_2010)\n",
        "files_2010 = [f for f in files_2010 if os.path.isfile(os.path.join(path_2010, f))]\n",
        "files_2010.sort()\n",
        "for i in tqdm(range(len(files_2010)), desc=\"Processing files\"):\n",
        "    # load image\n",
        "    file_2010 = os.path.join(path_2010, files_2010[i])\n",
        "    img = cv2.imread(file_2010)\n",
        "    # preprocessing for OCR\n",
        "    header = img[50:250, 10:-10]\n",
        "    gray_image = cv2.cvtColor(header, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary_image = cv2.threshold(gray_image, 245, 255, cv2.THRESH_BINARY)\n",
        "    gray_image_inv = cv2.bitwise_not(binary_image)\n",
        "    pil_image = Image.fromarray(gray_image_inv)\n",
        "    # OCR\n",
        "    tools = pyocr.get_available_tools()\n",
        "    tool = tools[0]\n",
        "    txt = tool.image_to_string(\n",
        "        pil_image,\n",
        "        lang=\"jpn\",\n",
        "        builder=pyocr.builders.TextBuilder(tesseract_layout=6)\n",
        "    )\n",
        "    filtered_text = re.findall(r'\\d+', txt)\n",
        "    if len(filtered_text) > 0:\n",
        "            if len(filtered_text[0]) == 4:\n",
        "                    path_save_2010 = path_renamed + \"2010_\" + filtered_text[0] + \".png\"\n",
        "                    cv2.imwrite(f\"{path_save_2010}\", img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gr7cw6AMhAf"
      },
      "source": [
        "## crop org chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMZft8ICMhAf"
      },
      "outputs": [],
      "source": [
        "files_renamed = os.listdir(path_renamed)\n",
        "files_renamed = [f for f in files_renamed if os.path.isfile(os.path.join(path_renamed, f))]\n",
        "files_renamed.sort()\n",
        "model = lp.Detectron2LayoutModel('lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config',\n",
        "                                 extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],\n",
        "                                 label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3:\"Table\", 4:\"Figure\"})\n",
        "\n",
        "\n",
        "for j in tqdm(range(1,len(files_renamed)), desc=\"Processing files\"):\n",
        "    # load image\n",
        "    file = os.path.join(path, files_renamed[j])\n",
        "    img = cv2.imread(file)\n",
        "    # detection\n",
        "    layout = model.detect(img)\n",
        "    lp.draw_box(img, layout, box_width=3)\n",
        "    figures = [block for block in layout if block.type == \"Figure\"]\n",
        "\n",
        "    # crop\n",
        "    for i, figure in enumerate(figures):\n",
        "        x_1, y_1, x_2, y_2 = map(int, figure.coordinates)\n",
        "        cropped_img = img[480:y_2, 50:x_2]\n",
        "        path_save = path_cropped + \"cropped_\" + file\n",
        "        cv2.imwrite(f\"{path_save}\", cropped_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rFc0OYVMhAg"
      },
      "source": [
        "## Detect departments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv7PYQg9MhAg"
      },
      "outputs": [],
      "source": [
        "# set train data\n",
        "register_coco_instances(\"org_chart_train\", {}, path_coco, path_train)\n",
        "\n",
        "# setting for using the model\n",
        "cfg = get_cfg() # initialize\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"org_chart_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.SOLVER.IMS_PER_BATCH = 1\n",
        "cfg.SOLVER.BASE_LR = 0.0004\n",
        "cfg.SOLVER.MAX_ITER = (500)\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (128)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "\n",
        "# train\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True) # for output\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0JB9rHXMhAg"
      },
      "outputs": [],
      "source": [
        "# the function for making the meta-data dict of the test data\n",
        "def get_test_dicts(img_dir):\n",
        "    img_files = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "    dataset_dicts = []\n",
        "    for idx, img_file in enumerate(img_files):\n",
        "        record = {}\n",
        "        record[\"file_name\"] = img_file\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"], record[\"width\"] = cv2.imread(img_file).shape[:2]\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts\n",
        "\n",
        "# change the test data form for dectron2\n",
        "DatasetCatalog.register(\"org_chart_data\", lambda: get_test_dicts(path_data))\n",
        "MetadataCatalog.get(\"org_chart_data\").set(thing_classes=[\"department\"])\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # load trained weights\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6  # score\n",
        "cfg.DATASETS.TEST = (\"org_chart_data\", )  # set the test data to the model\n",
        "\n",
        "# detect departments\n",
        "predictor = DefaultPredictor(cfg)\n",
        "metadata = MetadataCatalog.get(\"org_chart_data\")\n",
        "dataset_dicts = DatasetCatalog.get(\"org_chart_data\")\n",
        "\n",
        "for d in tqdm(dataset_dicts):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(img)\n",
        "    json_output = {\n",
        "    \"file_name\": d[\"file_name\"],\n",
        "    \"pred_boxes\": outputs[\"instances\"].pred_boxes.tensor.cpu().numpy().tolist(),\n",
        "    \"scores\": outputs[\"instances\"].scores.cpu().numpy().tolist(),\n",
        "    \"pred_classes\": outputs[\"instances\"].pred_classes.cpu().numpy().tolist()\n",
        "    }\n",
        "    # save JSON\n",
        "    base_name = os.path.basename(d[\"file_name\"])\n",
        "    json_name = base_name.replace(\".png\", \".json\")\n",
        "    json_path = os.path.join(path_json, json_name)\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump(json_path, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qos9jeIMhAg"
      },
      "outputs": [],
      "source": [
        "files_croppedd = os.listdir(path_cropped)\n",
        "files_croppedd = [f for f in files_croppedd if os.path.isfile(os.path.join(path_cropped, f))]\n",
        "\n",
        "files_json = os.listdir(path_json)\n",
        "files_json = [f for f in files_json if os.path.isfile(os.path.join(path_json, f))]\n",
        "\n",
        "results = []\n",
        "\n",
        "for i in tqdm(range(len(files_croppedd)), desc=\"Processing files\"):\n",
        "    file = os.path.join(path, files_croppedd[i])\n",
        "    file_json = os.path.join(path_json, files_json[i])\n",
        "    image = Image.open(file)\n",
        "    image_width, image_height = image.size\n",
        "    with open(file_json, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    # the coordation of the centers of department\n",
        "    centers = []\n",
        "    for i, box in enumerate(data[\"pred_boxes\"]):\n",
        "        x_center = int((box[0] + box[2]) / 2)\n",
        "        y_center = int((box[1] + box[3]) / 2)\n",
        "\n",
        "        # Normalize the image size\n",
        "        x_normalized = (x_center / image_width) * 10\n",
        "        y_normalized = (y_center / image_height) * 10\n",
        "        centers.append({\"id\": i, \"center\": (x_normalized, y_normalized)})\n",
        "\n",
        "    # make graph\n",
        "    G = nx.Graph()\n",
        "    # Add nodes to graph\n",
        "    for center in centers:\n",
        "        G.add_node(center[\"id\"], pos=center[\"center\"])\n",
        "    # Add edges to graph\n",
        "    distance_threshold = 5\n",
        "    for i in range(len(centers)):\n",
        "        for j in range(i + 1, len(centers)):\n",
        "            dist = np.linalg.norm(np.array(centers[i][\"center\"]) - np.array(centers[j][\"center\"]))\n",
        "            if dist < distance_threshold:\n",
        "                G.add_edge(centers[i][\"id\"], centers[j][\"id\"], weight=dist)\n",
        "\n",
        "    pos = nx.get_node_attributes(G, \"pos\")\n",
        "\n",
        "    num_depart = len(centers)\n",
        "    shortest_length_path = nx.average_shortest_path_length(G)\n",
        "    match = re.search(r\"cropped_(\\d{4})_(\\d{4})\", file)\n",
        "    if match:\n",
        "        year = match.group(1)  # Extracts the year (e.g., \"2002\")\n",
        "        code = match.group(2)  # Extracts the code (e.g., \"7003\")\n",
        "    else:\n",
        "        year = None\n",
        "        code = None\n",
        "\n",
        "    results.append({\"code\": code, \"year\": year , \"shortest_path_length\": shortest_length_path, \"num_depart\": num_depart})\n",
        "\n",
        "data = pd.DataFrame(results)\n",
        "data.to_csv(os.path.join(path_clean, \"org_data.csv\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
