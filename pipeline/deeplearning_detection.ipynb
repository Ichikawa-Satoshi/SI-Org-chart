{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntr3kXD8Kg3o"
      },
      "source": [
        "### Please run with Google Colab with Good GPU\n",
        "<a href=\"https://colab.research.google.com/github/wakachii/SI-Org-chart/blob/main/pipeline/deeplearning_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "6P3gTVMDKg3q"
      },
      "outputs": [],
      "source": [
        "# Detectron2 has not released pre-built binaries for the latest pytorch (https://github.com/facebookresearch/detectron2/issues/4053)\n",
        "# so we install from source instead. This takes a few minutes.\n",
        "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "# Install pre-built detectron2 that matches pytorch version, if released:\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "#!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/{CUDA_VERSION}/{TORCH_VERSION}/index.html\n",
        "\n",
        "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "nDqe8fW1Kg3q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf86c9f-5aed-4300-fb3d-172204f889ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import cv2 as cv2\n",
        "import json\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "import detectron2\n",
        "from tqdm import tqdm\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "S_FTuJydKg3r",
        "outputId": "16ddfe67-709b-4c3d-b0d1-0ee63c5c4afc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01/10 13:28:18 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [01/10 13:28:18 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[01/10 13:28:18 d2.data.datasets.coco]: Loaded 8 images in COCO format from /content/drive/MyDrive/scan_org_charts/learning/Org_chart-1.json\n",
            "[01/10 13:28:18 d2.data.build]: Removed 0 images with no usable annotations. 8 images left.\n",
            "[01/10 13:28:18 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[01/10 13:28:18 d2.data.build]: Using training sampler TrainingSampler\n",
            "[01/10 13:28:18 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[01/10 13:28:18 d2.data.common]: Serializing 8 elements to byte tensors and concatenating them all ...\n",
            "[01/10 13:28:18 d2.data.common]: Serialized dataset takes 0.03 MiB\n",
            "[01/10 13:28:18 d2.data.build]: Making batched data loader with batch_size=1\n",
            "WARNING [01/10 13:28:18 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[01/10 13:28:18 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.mask_head.predictor.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01/10 13:28:18 d2.engine.train_loop]: Starting training from iteration 0\n",
            "[01/10 13:28:23 d2.utils.events]:  eta: 0:01:49  iter: 19  total_loss: 5.198  loss_cls: 0.719  loss_box_reg: 0.7316  loss_mask: 0.6913  loss_rpn_cls: 2.829  loss_rpn_loc: 0.3234    time: 0.2256  last_time: 0.2348  data_time: 0.0195  last_data_time: 0.0029   lr: 1.5585e-05  max_mem: 3673M\n",
            "[01/10 13:28:28 d2.utils.events]:  eta: 0:01:47  iter: 39  total_loss: 2.444  loss_cls: 0.6446  loss_box_reg: 0.7936  loss_mask: 0.6362  loss_rpn_cls: 0.06763  loss_rpn_loc: 0.1968    time: 0.2390  last_time: 0.2025  data_time: 0.0067  last_data_time: 0.0056   lr: 3.1569e-05  max_mem: 3673M\n",
            "[01/10 13:28:34 d2.utils.events]:  eta: 0:01:47  iter: 59  total_loss: 2.114  loss_cls: 0.5368  loss_box_reg: 0.8027  loss_mask: 0.5177  loss_rpn_cls: 0.03972  loss_rpn_loc: 0.2012    time: 0.2521  last_time: 0.2422  data_time: 0.0112  last_data_time: 0.0029   lr: 4.7553e-05  max_mem: 3673M\n",
            "[01/10 13:28:38 d2.utils.events]:  eta: 0:01:39  iter: 79  total_loss: 1.957  loss_cls: 0.4857  loss_box_reg: 0.8099  loss_mask: 0.3883  loss_rpn_cls: 0.03579  loss_rpn_loc: 0.1556    time: 0.2463  last_time: 0.2347  data_time: 0.0043  last_data_time: 0.0044   lr: 6.3537e-05  max_mem: 3673M\n",
            "[01/10 13:28:43 d2.utils.events]:  eta: 0:01:33  iter: 99  total_loss: 1.78  loss_cls: 0.4336  loss_box_reg: 0.7959  loss_mask: 0.3133  loss_rpn_cls: 0.03751  loss_rpn_loc: 0.1631    time: 0.2415  last_time: 0.2321  data_time: 0.0031  last_data_time: 0.0026   lr: 7.9521e-05  max_mem: 3673M\n",
            "[01/10 13:28:48 d2.utils.events]:  eta: 0:01:33  iter: 119  total_loss: 1.615  loss_cls: 0.3799  loss_box_reg: 0.7394  loss_mask: 0.2956  loss_rpn_cls: 0.02857  loss_rpn_loc: 0.1532    time: 0.2493  last_time: 0.2259  data_time: 0.0122  last_data_time: 0.0131   lr: 9.5505e-05  max_mem: 3673M\n",
            "[01/10 13:28:53 d2.utils.events]:  eta: 0:01:27  iter: 139  total_loss: 1.441  loss_cls: 0.3421  loss_box_reg: 0.6874  loss_mask: 0.2415  loss_rpn_cls: 0.02868  loss_rpn_loc: 0.1344    time: 0.2467  last_time: 0.1504  data_time: 0.0040  last_data_time: 0.0029   lr: 0.00011149  max_mem: 3673M\n",
            "[01/10 13:28:58 d2.utils.events]:  eta: 0:01:21  iter: 159  total_loss: 1.353  loss_cls: 0.2987  loss_box_reg: 0.6623  loss_mask: 0.23  loss_rpn_cls: 0.02762  loss_rpn_loc: 0.1211    time: 0.2442  last_time: 0.2357  data_time: 0.0045  last_data_time: 0.0030   lr: 0.00012747  max_mem: 3673M\n",
            "[01/10 13:29:03 d2.utils.events]:  eta: 0:01:18  iter: 179  total_loss: 1.155  loss_cls: 0.2509  loss_box_reg: 0.5582  loss_mask: 0.1996  loss_rpn_cls: 0.02138  loss_rpn_loc: 0.1304    time: 0.2483  last_time: 0.3060  data_time: 0.0110  last_data_time: 0.0131   lr: 0.00014346  max_mem: 3673M\n",
            "[01/10 13:29:08 d2.utils.events]:  eta: 0:01:13  iter: 199  total_loss: 1.069  loss_cls: 0.2184  loss_box_reg: 0.489  loss_mask: 0.1836  loss_rpn_cls: 0.02238  loss_rpn_loc: 0.1224    time: 0.2482  last_time: 0.2229  data_time: 0.0088  last_data_time: 0.0034   lr: 0.00015944  max_mem: 3673M\n",
            "[01/10 13:29:13 d2.utils.events]:  eta: 0:01:07  iter: 219  total_loss: 0.8866  loss_cls: 0.2044  loss_box_reg: 0.4108  loss_mask: 0.1557  loss_rpn_cls: 0.008051  loss_rpn_loc: 0.1283    time: 0.2452  last_time: 0.2125  data_time: 0.0042  last_data_time: 0.0034   lr: 0.00017542  max_mem: 3673M\n",
            "[01/10 13:29:18 d2.utils.events]:  eta: 0:01:02  iter: 239  total_loss: 0.8554  loss_cls: 0.1946  loss_box_reg: 0.3483  loss_mask: 0.1497  loss_rpn_cls: 0.009504  loss_rpn_loc: 0.125    time: 0.2453  last_time: 0.2270  data_time: 0.0058  last_data_time: 0.0143   lr: 0.00019141  max_mem: 3673M\n",
            "[01/10 13:29:24 d2.utils.events]:  eta: 0:00:58  iter: 259  total_loss: 0.7814  loss_cls: 0.1803  loss_box_reg: 0.3392  loss_mask: 0.1471  loss_rpn_cls: 0.008393  loss_rpn_loc: 0.128    time: 0.2501  last_time: 0.1805  data_time: 0.0092  last_data_time: 0.0034   lr: 0.00020739  max_mem: 3673M\n",
            "[01/10 13:29:28 d2.utils.events]:  eta: 0:00:53  iter: 279  total_loss: 0.7393  loss_cls: 0.1536  loss_box_reg: 0.2987  loss_mask: 0.1434  loss_rpn_cls: 0.006085  loss_rpn_loc: 0.1072    time: 0.2483  last_time: 0.1377  data_time: 0.0032  last_data_time: 0.0031   lr: 0.00022338  max_mem: 3673M\n",
            "[01/10 13:29:33 d2.utils.events]:  eta: 0:00:48  iter: 299  total_loss: 0.7424  loss_cls: 0.1693  loss_box_reg: 0.2924  loss_mask: 0.1427  loss_rpn_cls: 0.007223  loss_rpn_loc: 0.1161    time: 0.2480  last_time: 0.2986  data_time: 0.0065  last_data_time: 0.0262   lr: 0.00023936  max_mem: 3673M\n",
            "[01/10 13:29:39 d2.utils.events]:  eta: 0:00:44  iter: 319  total_loss: 0.6604  loss_cls: 0.1295  loss_box_reg: 0.2692  loss_mask: 0.1312  loss_rpn_cls: 0.004195  loss_rpn_loc: 0.1154    time: 0.2494  last_time: 0.2214  data_time: 0.0087  last_data_time: 0.0032   lr: 0.00025534  max_mem: 3673M\n",
            "[01/10 13:29:43 d2.utils.events]:  eta: 0:00:38  iter: 339  total_loss: 0.6743  loss_cls: 0.1329  loss_box_reg: 0.3065  loss_mask: 0.1275  loss_rpn_cls: 0.004043  loss_rpn_loc: 0.101    time: 0.2478  last_time: 0.2348  data_time: 0.0048  last_data_time: 0.0154   lr: 0.00027133  max_mem: 3673M\n",
            "[01/10 13:29:48 d2.utils.events]:  eta: 0:00:33  iter: 359  total_loss: 0.6821  loss_cls: 0.1363  loss_box_reg: 0.2844  loss_mask: 0.1478  loss_rpn_cls: 0.004432  loss_rpn_loc: 0.1252    time: 0.2468  last_time: 0.2734  data_time: 0.0033  last_data_time: 0.0042   lr: 0.00028731  max_mem: 3673M\n",
            "[01/10 13:29:54 d2.utils.events]:  eta: 0:00:29  iter: 379  total_loss: 0.652  loss_cls: 0.1181  loss_box_reg: 0.2682  loss_mask: 0.1322  loss_rpn_cls: 0.003545  loss_rpn_loc: 0.1171    time: 0.2498  last_time: 0.2751  data_time: 0.0130  last_data_time: 0.0070   lr: 0.0003033  max_mem: 3673M\n",
            "[01/10 13:29:58 d2.utils.events]:  eta: 0:00:24  iter: 399  total_loss: 0.6295  loss_cls: 0.1143  loss_box_reg: 0.2633  loss_mask: 0.1259  loss_rpn_cls: 0.005211  loss_rpn_loc: 0.1172    time: 0.2492  last_time: 0.2234  data_time: 0.0045  last_data_time: 0.0030   lr: 0.00031928  max_mem: 3673M\n",
            "[01/10 13:30:03 d2.utils.events]:  eta: 0:00:19  iter: 419  total_loss: 0.6227  loss_cls: 0.1118  loss_box_reg: 0.2369  loss_mask: 0.1328  loss_rpn_cls: 0.006942  loss_rpn_loc: 0.1098    time: 0.2485  last_time: 0.3262  data_time: 0.0044  last_data_time: 0.0061   lr: 0.00033526  max_mem: 3673M\n",
            "[01/10 13:30:09 d2.utils.events]:  eta: 0:00:14  iter: 439  total_loss: 0.6254  loss_cls: 0.113  loss_box_reg: 0.2524  loss_mask: 0.1262  loss_rpn_cls: 0.004264  loss_rpn_loc: 0.1087    time: 0.2493  last_time: 0.2504  data_time: 0.0113  last_data_time: 0.0129   lr: 0.00035125  max_mem: 3673M\n",
            "[01/10 13:30:14 d2.utils.events]:  eta: 0:00:09  iter: 459  total_loss: 0.6172  loss_cls: 0.1276  loss_box_reg: 0.2253  loss_mask: 0.1169  loss_rpn_cls: 0.006413  loss_rpn_loc: 0.09214    time: 0.2504  last_time: 0.1947  data_time: 0.0100  last_data_time: 0.0146   lr: 0.00036723  max_mem: 3673M\n",
            "[01/10 13:30:18 d2.utils.events]:  eta: 0:00:04  iter: 479  total_loss: 0.6112  loss_cls: 0.1105  loss_box_reg: 0.2407  loss_mask: 0.1162  loss_rpn_cls: 0.005307  loss_rpn_loc: 0.1177    time: 0.2492  last_time: 0.2330  data_time: 0.0041  last_data_time: 0.0029   lr: 0.00038322  max_mem: 3673M\n",
            "[01/10 13:30:25 d2.utils.events]:  eta: 0:00:00  iter: 499  total_loss: 0.6179  loss_cls: 0.1114  loss_box_reg: 0.2296  loss_mask: 0.1301  loss_rpn_cls: 0.004829  loss_rpn_loc: 0.1378    time: 0.2495  last_time: 0.2995  data_time: 0.0050  last_data_time: 0.0125   lr: 0.0003992  max_mem: 3673M\n",
            "[01/10 13:30:26 d2.engine.hooks]: Overall training speed: 498 iterations in 0:02:04 (0.2495 s / it)\n",
            "[01/10 13:30:26 d2.engine.hooks]: Total training time: 0:02:06 (0:00:02 on hooks)\n"
          ]
        }
      ],
      "source": [
        "path = \"/content/drive/MyDrive/scan_org_charts/learning\"\n",
        "path_train = path + \"/data/train\"\n",
        "path_coco = path + \"/Org_chart-1.json\"\n",
        "path_data = \"/content/drive/MyDrive/scan_org_charts/cropped\"\n",
        "# set train data\n",
        "register_coco_instances(\"org_chart_train\", {}, path_coco, path_train)\n",
        "\n",
        "# setting for using the model\n",
        "cfg = get_cfg() # initialize\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"org_chart_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.SOLVER.IMS_PER_BATCH = 1\n",
        "cfg.SOLVER.BASE_LR = 0.0004\n",
        "cfg.SOLVER.MAX_ITER = (500)\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (128)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "\n",
        "# train\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True) # for output\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "uBZjAShvKg3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79225dac-779c-4fcc-e680-9b20d003b255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01/10 13:31:18 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from ./output/model_final.pth ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
          ]
        }
      ],
      "source": [
        "# the function for making the meta-data dict of the test data\n",
        "def get_test_dicts(img_dir):\n",
        "    img_files = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "    dataset_dicts = []\n",
        "    for idx, img_file in enumerate(img_files):\n",
        "        record = {}\n",
        "        record[\"file_name\"] = img_file\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"], record[\"width\"] = cv2.imread(img_file).shape[:2]\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts\n",
        "\n",
        "# change the test data form for dectron2\n",
        "# DatasetCatalog.register(\"org_chart_data\", lambda: get_test_dicts(path_data))\n",
        "MetadataCatalog.get(\"org_chart_data\").set(thing_classes=[\"department\"])\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # load trained weights\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6  # score\n",
        "cfg.DATASETS.TEST = (\"org_chart_data\", )  # set the test data to the model\n",
        "\n",
        "# detect departments\n",
        "predictor = DefaultPredictor(cfg)\n",
        "metadata = MetadataCatalog.get(\"org_chart_data\")\n",
        "dataset_dicts = DatasetCatalog.get(\"org_chart_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "rRuY2farKg3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7149ef7a-11c1-478e-d5a1-7f97bccb98f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 101/101 [00:28<00:00,  3.51it/s]\n"
          ]
        }
      ],
      "source": [
        "output_path = \"/content/drive/MyDrive/scan_org_charts/learning/output\"\n",
        "for d in tqdm(dataset_dicts):\n",
        "    outputs = predictor(img)\n",
        "    json_output = {\n",
        "    \"file_name\": d[\"file_name\"],\n",
        "    \"pred_boxes\": outputs[\"instances\"].pred_boxes.tensor.cpu().numpy().tolist(),\n",
        "    \"scores\": outputs[\"instances\"].scores.cpu().numpy().tolist(),\n",
        "    \"pred_classes\": outputs[\"instances\"].pred_classes.cpu().numpy().tolist()\n",
        "    }\n",
        "    # save JSON\n",
        "    base_name = os.path.basename(d[\"file_name\"])\n",
        "    json_name = os.path.splitext(base_name)[0] + \".json\"\n",
        "    json_path = os.path.join(output_path, json_name)\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump(json_output, f)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}